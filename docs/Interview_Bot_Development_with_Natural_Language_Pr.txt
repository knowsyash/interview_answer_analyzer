International Journal of Technology 13(2) 274-285 (2022)
Received July 2021 / Revised September 2021 / Accepted December 2021

International Journal of Technology

http://ijtech.eng.ui.ac.id

Interview Bot Development with Natural Language Processing and Machine Learning
Joko Siswanto1*, Sinung Suakanto2, Made Andriani1, Margareta Hardiyanti2, Tien Fabrianti Kusumasari2
1Industrial Management Research Group, Industrial Technology Faculty, Bandung Institute of Technology, Jl. Ganesa 10, Bandung 40132, Indonesia
2Cybernetics Research Group, Telkom University, Jl. Telekomunikasi No.1, Kab. Bandung 40257, Indonesia


Abstract. Interview for competency assessment takes essential roles in Human Resource Management practices. However, the traditional competency interview process needs considerable time and costs and often requires face-to-face meetings that may endanger both interviewers and interviewees during a pandemic. This study aims to present the development of an interview bot for identifying competency based on the Behavioural Event Interview method by using artificial intelligence technology. It is an automation of the interview process to explore a person’s competencies levels based on past behavioural experiences. The development of the interview bot involved two main activities. The first is the data training process to develop learning models to determine competency levels based on provided valid participant’s responses. The second is the testing and evaluation model for assessment to determine competency levels. We found that our method can predict a person's competence levels based on their responses. Our approach can make predictions with acceptable accuracy. The interview bot is a valuable and reliable tool to conduct online interviews and support the assessment centre process, especially with conditions of physical and social distancing constraints. It provides flexibility in terms of time and place for participants, and its process is delivered in Indonesia's Language. The interview bot is more cost efficient than traditional interviews with the same behavioural event interview methods, and it would also be preferable for millennials.
Keywords: Artificial intelligence; Behavioural event interview; Chat bot; Interview bot; Machine learning

    1. Introduction
Recognizing the importance of competencies for competitive advantages, the Government of Indonesia (GOI), as a policymaker, issued regulations that encourage both governmental and private business organizations to increase employee competencies. One of the government’s regulations is the Decree of the Employment Minister of the Republic of Indonesia, Number 2 of 2016, concerning the National Work Competency Standardization System. The statute contains a comprehensive and synergic arrangement of national work competency standards intended to improve Indonesian human resources competencies. With the issuance of the regulation, Indonesian workers must meet the established competency standards to be able to work in an organization. Therefore,

*Corresponding author’s email: j.siswanto@ti.itb.ac.id, Tel.: +62-22-2508149; Fax: +62-22-2508149 doi: 10.14716/ijtech.v13i2.5018

organizations must regularly conduct competency assessments.
One of the techniques that organizations can use to perform competency assessments is a behavioural event interview (BEI). BEI is a systematic interviewing method that is carried out in five stages: introducing and explaining the interview process, extracting information about job responsibilities, extracting information about behavioural events, exploring the characteristics required for the job, and finally, drawing conclusions and summaries. In contrast to ordinary interviews, which are considered less reliable in predicting candidates who will perform well, BEIs can reveal detailed behavioural descriptions of how someone does their job and thus overcome the ineffectiveness of typical interviews. However, although BEI is a suitable method for measuring competencies, it also has some weaknesses. For example, the interview process takes longer, requires many certified interviewers—trained experts are still limited in number— requires high organizing costs, and introduces potential interviewer bias in the assessment. Meanwhile, the need for conducting competency assessment increases in line with the growing awareness of conducting competency assessment in companies and organizations. In conducting BEIs, interviewers look for clues about the interviewee’s past experiences. In English, these can be identified from past-tense responses. However, Indonesian grammar is simple in the sense that it has no past-tense pattern. Instead, it uses keywords that indicate the time or frequency of one’s actions. Therefore, developing an interview bot that “speaks” Indonesian presents a different challenge and requires a different approach. The fourth Industrial Revolution has impacted automation technology development in various fields, and technological advances are being integrated in every aspect of our lives (Berawi, 2018). Artificial intelligence (AI) facilitates decision-making, creates integrative systems, and simplifies complex mechanisms though automation (Berawi, 2020). There are AI applications in many fields, including human resource management systems. AI refers to machines’ ability to perform tasks usually associated with human thinking, especially by using computer systems. AI allows computers to learn from and make decisions or recommend actions based on available data and helps to solve
complex problems. AI applications can support repetitive or patterned processes.
Likewise, human resource management (HRM) is a viable field in which to implement automation technology, for example, in chatbots as part of the interview process. The weaknesses of BEI could be minimized by developing an interview bot as a substitute for or accompaniment to interviewers or appraisers. Moreover, such bots could conduct interviews remotely, reducing interview costs and increasing time flexibility.
Eubanks (2017) reported that experimenting with short message service (SMS)-based interactions aids in interview scheduling provided benefits. Further, the process was undertaken by a bot, not a person. It has also been found that candidates primarily interact with the interview bots outside of regular office hours. Thus, the recruiters do not have to work overtime, as parts of the interview process could be taken over by bots. In a typical automatic talent acquisition process, the candidates interact with an interview bot, allowing the recruiters to engage in other activities simultaneously. Recruitment chatbots cannot respond to questions that are not expected. This could be handled by a program that sends the questions directly to the staff responsible for answering them. Hence, the way in which AI is used today in the recruitment process is intended to leverage the benefits of implementing bots in various ways.
The interview bot application for assessing competency levels is a further development of chatbot technology. A chatbot is a computer system that operates as an interface between human users and software applications, using natural written and oral language to communicate. Some examples of chatbots that have been developed are Siri, IBM Watson,

and Google Assistant. A chatbot has several advantages, including ease of access, efficiency, availability, scalability, cost, and insight. Chatbot technology has been applied in various fields, such as handling e-commerce queries (Pricilla et al., 2018), web shopping helpers, hotel reservation agents, and FAQ agents (Siddig & Hines, 2019), and various digital consumers (Rese et al., 2020). However, chatbot applications for supporting HRM practices remain underdeveloped.
A chatbot architecture can be further developed to have an information retrieval function and interactively “generate” questions by applying AI technology. This may work in two ways and can support artificial interviews (Suakanto et al., 2021). AI technology includes machine learning, deep learning, neural networks, and natural language processing (NLP). Cowgill (2018) used machine learning for hiring white-collar workers. The challenge of developing AI and machine learning for HRM is related to the number of data sets, which tends to be relatively small by data science standards (Tambe et al., 2019). As a branch of AI, NLP has been employed in human interview systems. An interactive interview bot system based on NLP was developed to conduct interviews and generate results automatically (Yakkundi et al., 2019). One of the critical benefits of NLP is its ability to process and understand unstructured text data automatically.
Conducting competency assessments using interview bots provides many advantages. The interview process is conducted with prospective job applicants or employees, who will be assessed for competencies by bots that have been designed to present adaptive multilevel interview questions and have the ability to analyse the initial competency level from the answers given. It is expected that an interview bot will consistently assess competency levels to reduce interviewers’ subjective bias. Interview bots may also provide a suitable interface for millennials, who prefer to interact with the help of intelligent computer applications. Moreover, during the pandemic, in which face-to-face interviews need to be avoided or at least minimized, interview bots will substantially contribute to preventing the spread of viruses through face-to-face interview processes. In addition, interview bots will allow companies to increase their assessment capacity and reduce interview costs. This study presents an interview bot application using the BEI method for interview text in the Indonesian language that helps organizations and companies assess competency levels more accurately and efficiently. This research focuses on developing a text-based interview bot algorithm for competency assessment and evaluating its performance.

    2. Design and Methods
The design and development method of an interview bot based on BEI in Indonesian requires a specific approach since the language does not use the past tense. The interview bot design presented in this paper is based on our previous study (Suakanto et al., 2021).
        2.1. Flow Design
The interview bot is designed to assess people’s competency levels and facilitate the interview process. It provides accurate and objective results yet requires less time and costs less. This interview bot system has a camera to monitor the user’s face from the beginning until the end of the interview process. The interviewees need to respond to the generated questions, and the system will record and map their competency levels almost simultaneously.
The developed interview bot has three main stages following the BEI process. The first is an introduction. Then, the interview bot greets the interviewee and explains the interview procedure to make the interviewee feel comfortable and confident before

responding to questions. The interviewee also needs to answer several questions for validation purposes in this introduction. Finally, when the system determines that the interviewee is registered and valid, the process continues; otherwise, they need to return to the registration process or report to the HR department. The second stage is the competency assessment process. The interview bot prepares open questions based on the situation, task, actions, and results (STAR) structure. Soon after each inquiry is completely responded to, the system will record, analyze, and provide the competency levels according to the learned algorithm. This process is repeated until all required measuring competencies are completed in line with the competency dictionary provided. The final stage is validating the results and closing the session. Interviewees will be shown the descriptions of their competency levels based on the interview bot’s diagnosis. When the interviewees agree with the results, the final competency levels will be recorded. Otherwise, interviewees’ concerns will be recorded and reanalyzed by the system or provided to assessors for further manual analyses. At the closing of the session, the system will inform the interviewee that any information provided during the assessment is kept confidential and solely used for official purposes. No data can be read or copied by an unauthorized person. The simplified flow design for the interview bot is shown in Figure 1.

Figure 1 Design flow of the interview bot
The interview bot’s development process is conducted involves two main activities following typical AI engineering process. The first is the training process to develop a model to determine competency levels. This training process includes gathering competency data from valid participant responses, preparing data for training inputs, choosing a suitable model, and performing data training. The second is testing and evaluation. This process covers the evaluation of model outputs, hyperparameter tuning, and finally, model usage for predicting competency levels.
        2.2. Data Training Method
The data training process is performed by implementing the NLP approach and statistical analyses to construct the models. It uses available datasets from the valid responses of the conventional BEI process and the data acquired directly from applications (DAC). The data set includes the competency levels scored by certified professional assessors. The data training is initiated by performing tokenization in the sentences

frequently used in NLP. Then, Bayesian inference, one of the most popular statistical techniques, is applied. With Bayesian interference, the prior probabilities of an event are updated when new data are gathered. The applied data training method is presented in Figure 2.

Figure 2 Method for data training
Figure 3 illustrates the details of the initial process when implementing NLP with an example in Indonesian. Tokenizing (i.e., splitting a sentence into words) is performed at the beginning of the data training process. This is followed by data cleaning and reduction. These operations discard the stop words as well as unnecessary symbols or words to reduce data noise. Afterwards, a stemming process is performed to change each word into its basic form. For example, in Indonesian, the word “memberi” (giving) is transformed into its basic form, “beri” (to give). Then, part-of-speech (POS) tagging is carried out for each word to determine its role within a sentence, such as a verb or a noun. In this study, word tagging is used as a multiplier factor, and verbs are assigned the highest weight value compared to the other kinds of words.

Figure 3 Initial process of NLP Implementation

In the next stage, the computation of term frequency (TF) is applied to every keyword of competency levels. If a word appears more frequently, it will get more weight or higher probability. TF and inverse TF (IDF) are prevalent feature extraction techniques. They are used as a statistical measure to represent the importance level of the words in a set of sentences or documents. Equation 1 shows the formula to compute TF.
𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑡𝑖𝑚𝑒 𝑤𝑜𝑟𝑑 𝑎𝑝𝑝𝑒𝑎𝑟𝑠 𝑖𝑛 𝑡ℎ𝑒 𝑑𝑜𝑐𝑢𝑚𝑒𝑛𝑡
𝑇𝐹 =


𝑇𝑜𝑡𝑎𝑙 𝑤𝑜𝑟𝑑𝑠 𝑖𝑛 𝑡ℎ𝑒 𝑑𝑜𝑐𝑢𝑚𝑒𝑛𝑡𝑠
or
𝑇𝐹 = 𝑃𝑚,𝑖
= 𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑡𝑖𝑚𝑒 𝑤𝑜𝑟𝑑𝑚,𝑖
𝑇𝑜𝑡𝑎𝑙 𝑤𝑜𝑟𝑑𝑠 𝑖𝑛 𝑙𝑒𝑣𝑒𝑙 𝑚
(1)
where Pm,i is the TF of competency level m and word i.
Table 1 shows the collection of the words along with the frequency of each word in level 1 of competency A and the TF computation results.
Table 1 The collection of words in level 1 of competency A

No	Word	Frequency	TF Pm
1	give	2	0.2
2	do	3	0.3
	3	lead	5	0.5
Then, the TF result is stored in the collection of words. For example, Figure 4 shows the applied model, where each competency level has a set of words and TF results. This set of data is called the applied model, which will be used in the training process.

Figure 4 The applied model contains competency levels and their sets of words and TF results
        2.3. Testing Method

Figure 5 Proposed testing method

After the applied model is formed, the testing and evaluation process can be conducted. The developed model is the word collection for each level and each competition. The dataset contains the keywords and the weight (Pm,i), where m shows the level, and i shows the keyword in ith at the associated competency level. The proposed testing method is shown in Figure 5.
The testing is carried out by implementing the NLP process following a similar process as in the training stage. In this stage, the NLP process will produce keywords that keep the scores computed on each level. After the keywords are obtained, we can count the value of each competency level, which represents the TF of competency level m. Then, the formula in Equation 2 is applied to calculate the score on each level.
Pm   Pm,i
i
(2)
where Pm is the total weight level at competency m, ( Pm,i ), where weight at competency level m word i.
The proposed competency level is the competency level that has the maximum score
out of all levels. Therefore, the competence level is formulated by Equation 3.
L  max( Pm )
where L is the competence level, and Pm is the total weight level at competency m.
(3)
From the computation, each competency level is given a score. For example, based on Figure 6, P1 = 0.56, P2 = 0.34, P3 = 0.12, and P4 = 0. Hence, it can be seen that P1 has the highest score in level 1 (max), which we mark with max* in Figure 6. Thus, the machine will conclude that the competency level is level 1 because P1 is the highest score.
        2.4. All-Zero Result Condition
In several cases, the computation of all competency levels will result in a score of 0 for all competency levels. This condition is called the “all-zero result”. For example: P1 = 0, P2
= 0, P3 = 0, and P4 = 0. This condition is interpreted as the machine being “incapable” of producing the score or predicting competency levels. The likely reason for this is that the interviewee’s answer is too short, inconsequential, or irrelevant to the question. This situation also indicates no keyword match between the set of “keywords” extracted from the interviewee’s response and the set of keywords in the competency dictionary. In actual practice, this situation also may occur in conventional assessment scoring. In a traditional assessment of competency, there is a condition that the assessor cannot determine the level of competency based on the snippet of a response. This condition occurs when the interviewee does not answer questions following the STAR structure. Primarily, they respond to questions too generally or briefly or do not meet expectations. In this situation, assessors may leave the score empty (blank) to prevent ambiguity in perceiving the lowest score. Hence, the interviewee’s data or the answers cannot be used to form the conclusion. In such a case, we suggest a parameter to calculate the number of data interpretable by a machine or the other way around (produce an all-zero result). It is important to note that an empty or blank “score” is not the same as competency level 0 (zero). The competency level zero means neutral, while the level blank means the competency level cannot be determined by the interview bot or the assessors.
        2.5. Evaluation Method
A new evaluation metric is suggested for the evaluation of our interview bot for competency level measurement. It relates to the number of data that can be interpreted by machine learning. We propose the concept of coverage, which shows the number of

interpretable records compared to the total records. Thus, the formula which represents the coverage is shown in Equation 4.
C 		Ni Ni Nu
(4)
where C is the coverage, Ni is the number of interpretable records, and Nu is the number of uninterpretable records.
Having the coverage, we can set accuracy as the parameter success of this method.
Accuracy is also included as an essential factor of NLP and machine learning. The accuracy formula is presented in Equation 5.
A 	Na
Na Nx

(5)
where A is the accuracy, Na is the number of accurate records, and N x is the number of inaccurate records.
    3. Results and Discussion
        3.1. Application
We developed the interview bot for the Indonesian language using NLP and machine learning. Figure 6 presents examples of questions related to the competency of integrity. An interviewee will answer according to the questions given. The system will record the answers and process the answers to count or predict competency and competency scores.



Figure 6 Example of the bot asking questions and an interviewee giving feedback or answering the bot in Indonesian, with translation

        3.2. Testing Scenario
For testing purposes, two sets of data from different groups were prepared. The first set (Set A) was collected using the interview bot application. Fifty-two (52) people participated in this competency assessment process. The second set of data (Set B) used 1153 past historical records taken from the written BEI competency mapping method using a similar STAR interview structure. One of the challenges in this research was obtaining datasets related to the level of competency, so there was a limited amount of data. In our first study, we used a total of 1205 full set data.
Data A were collected from homogenous respondents, who are accustomed to interacting with computers, while data B were taken from respondents of various ages (21– 55 years) and cultural backgrounds working in government offices. The data are presented in Indonesian, and the participant also responds in Indonesian. The data are complemented with the other data and labels from the expert assessor. Some snippets of the answers can be seen in Table 2. The table shows an example of participants’ answers and the label given by the assessors that convey the interviewee’s score.

Table 2 Example snippet of answers and competency level provided by assessors

Group Data	Employee	Competency	Snippet of Answers	Competency level
A	1	Teamwork	Regarding disciplinary issues with working hours and main tasks, I always remind my colleagues to obey disciplinary issues and main duties as assistant.	2
A	2	Result Oriented	When implementing performance, I try to describe the performance that exceeds the set target. By combining several regulations that serve as guidelines, the performance description can be developed as expected.	3
A	3	Communicati on	I was once given the task by my leader to hold a reconciliation meeting related to the district government official vehicles, at that time I carried out this task by inviting all goods managers from all OPDs of the District Government.	4
B	4	Integrity	I provide a good example in the work environment to comply with all the rules, norms that apply so that my stakeholders and subordinates seem to enforce discipline both when they enter the office and with the tasks that have been given.	2
B	5	Result Oriente	For example, in setting a target income per UPT in my OPD scope, it is usually higher than the number set in the DPA to spur the performance of friends at UPT in terms of achieving targets.	2
B	6	People Development	When I prepared the mapping and evaluation activities of the scope of ASN, the first thing I directed to my staff was to collect a database of employees who met the requirements to become participants. I did not give a deadline for the completion of the work, and as a result, I have not received the data for some time because the activity is still scheduled
for a few months.	2
We can also perform the experiments using the split-half concept—that is, splitting into two parts—by leveraging this technique. This splitting can be performed on cross-testing for both data training and data testing. For example, when the data training uses group data A, data testing applies group data B. The combination of group data training and testing will be used to determine the characteristics of the result and to know the accuracy. The testing result can be seen in the result section.
        3.3. Performance Results
The AI approach is also used to map and evaluate participant’s answers into specific competency values. The interview bot will automatically assess the participant’s responses

and compare the results to the results assessed by human experts. If the gap between the interview bot and human judgment is too large, the robot is considered incapable of mapping the results. Conversely, if the difference between the assessments of robots and human experts is small, it means that the robot be able to perform competency assessments. Table 3 illustrates comparisons of competency levels provided by the interview bot and assessors.
Table 3 Illustration of competency levels provided by interview bot and assessors

Group Data	Employee	Competency	Assessor Score	Interview Bot Score	Difference	Status
A	1	Teamwork	2	2	0	Accurate
A	2	Result Oriented	3	1	-2	Inaccurate (Under)
A	3	Communication	4	4	0	Accurate
B	4	Integrity	2	2	0	Accurate
B	5	Result Oriented	2	2	0	Accurate
B	6	People Development	2	4	2	Inaccurate (Over)
The result displayed in Table 3 shows four accurate results and two inaccurate results.
Thus, the accuracy A is [4:(4+2)]x100% = 66.7%.
The experiments are carried out by forming a combination between the different groups of data to identify the characteristics of the learning model. For instance, the data training uses group data A, and then the data testing uses group data B. The combination is then carried out between data training and data testing to obtain the characteristics of the learning process and accuracy. The performance results can be seen in Table 4.
Table 4 Performance evaluation

No	Data Training	Data Testing	Coverage (C)	Accuracy (A)	Over Judgment	Under Judgment
1	A	A	98.1%	96.1%	3.9%	0.0%
2	A	A&B	39.9%	72.8%	10.4%	16.8%
3	A	B	37.3%	70.0%	11.2%	18.8%
4	B	B	96.0%	79.3%	15.5%	5.1%
5	B	A&B	95.8%	78.1%	16.6%	5.4%
6	B	A	90.4%	48.9%	40.4%	10.6%
7	A&B	A	98.1%	64.7%	27.5%	7.8%
8	A&B	B	96.0%	79.0%	16.3%	4.7%
9	A&B	A&B	96.1%	78.4%	16.8%	4.8%
        3.4. Discussion
AI has been researched for use in developing the next generation of HRM (Margherita, 2021; Pereira, 2021). Robots or chatbots have been considered for recruitment and Selection in HRM (Pereira, 2021). The developed interview bot, as a further enhancement of a chatbot, provides better performance. Based on our experiments, the interview bot provides good and acceptable outcomes with more than 70% accuracy. The highest accuracy was achieved when both training and testing data were taken from the same data set. For example, if both training and testing use data group A, the coverage value is 98.1 %, and the accuracy is 96 %. Similarly, when data group B is used for both the data training and data testing, the coverage is 96%, and the accuracy is 79 %. The accuracy of data group B is a bit lower than that of data group A. This is because data group B is comprised of traditional BEI manuscripts.
A challenge occurs when the data training and data set are crossing. For example, when the training uses data A and the testing uses data B, the experiment delivers 70% accuracy and 37% coverage. This accuracy value is good enough, although the coverage is decreased compared to when the data training and data testing use the same data. When data B is used

for data training and the data testing uses data A, the accuracy is 48% with a 90% coverage. This condition is unique, as the coverage is increased but the accuracy is decreased. Hence, the variability of data training is a crucial part of the learning process.
In the following scenario, if all the data (A & B) is used for data training, it could generate better coverage since the amount of data learning is greater. When all data are used for data training, the coverage value increases to 96.0% to 98.1%. The accuracy is better than the lower limit, which is 64.7%. The highest accuracy only reaches 79%.
This study found that the degree of data variability determines the machine learning process. Therefore, adding to the amount of data training does not guarantee that the accuracy will increase. Still, the coverage is expected to increase. This study could support the development of interview bots for interviewing without human assistance. While the accuracy is less than 90%, the study can be used as a starting point to develop competence mapping based on an interview bot and machine learning. As the interview bot is used more often and more situations, its accuracy will improve. Our findings support Reilly’s (2018) conclusion that incorporating AI at work can make employee recruitment processes faster and more effective. Furthermore, Margherita et al. (2021) also noted that the positive impacts of digital technology on HRM include conversational AI and hiring tools and talent experience management platforms.

    4. Conclusions
This study has successfully developed an interview bot that uses machine learning to determine the competence level of a person. In this research, we use an Indonesian language dataset. To converse with human participants, we use NLP technology. This study demonstrated very good accuracy in various scenarios. The results of this study can be used as the basis for developing an interview bot that is closer to professional interviews. One of the important aspects of this system is datasets. With a more extensive and comprehensive dataset, it is possible that the system would be richer in information and achieve better accuracy. For future works, the system could be enhanced to use voice interaction instead of text-based chat. The frequency, types, and depth of the questions could also be made more adaptive to match the psychological aspects of the interviewee.

References
Berawi, M.A., 2018. The Fourth Industrial Revolution: Managing Technology Development for Competitiveness. International Journal of Technology, Volume 9(1), pp. 1–4
Berawi,  M.A.,  2020.  Managing  Artificial  Intelligence  Technology  for  Added  Value.
International Journal of Technology, Volume 11(1), pp. 1–4
Cowgill, B., 2018. Bias and Productivity in Humans and Algorithms: Theory and Evidence from Résumé Screening. Working paper, Columbia University, New York
Eubanks, B., 2017. Artificial Intelligence for HR Use AI to Support and Develop a Successful Workforce.	Kogan	Page.	Available	online	at https://books.google.com/books?hl=en&lr=&id=hrN7DwAAQBAJ&oi=fnd&pg=PP1&d q=Artificial+Intelligence+for+HR+Use+AI+to+Support+and+Develop+a+Successful+ Workforce&ots=jc5-Zm6nbw&sig=rXBsT7SPUpQbJWXMAh6O9gDxsbo
Kim, S., Lee, J., Gweon, G., 2019. Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality. In: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, pp. 1–12

Margherita, A., 2021. Human Resources Analytics: A Systematisation of Research Topics and Directions for Future Research. Human Resource Management Review, Volume 32(2) p. 100795
Nawaz, N., Gomes, A.M., 2019. Artificial Intelligence Chatbots are New Recruiters. International Journal of Advanced Computer Science and Applications, Volume 10(9), pp. 1–5
Pereira, V., Hadjielias, E., Christofi, M., Vrontis, D., 2021. A Systematic Literature Review on the Impact of Artificial Intelligence on Workplace Outcomes: A Multi-Process Perspective. Human Resource Management Review, p. 100857
Pricilla, C., Lestari, D.P., Dharma, D., 2018. Designing Interaction for Chatbot-Based Conversational Commerce with User-Centered Design. In: 5th International Conference on Advanced Informatics: Concept Theory and Applications (ICAICTA), IEEE, pp. 244– 249
Reilly, P., 2018. The Impact of Artificial Intelligence on the HR Function. Institue for Employment	Studies.	Available	online	at	https://www.employment- studies.co.uk/system/files/resources/files/mp142_The_impact_of_Artificial_Intellige nce_on_the_HR_function-Peter_Reilly.pdf
Rese, A., Ganster, L., Baier, D., 2020. Chatbots in Retailers’ Customer Communication: How to Measure their Acceptance? Journal of Retailing and Consumer Services, Volume 56, p. 102176
Suakanto, S., Siswanto, J., Kusumasari, T.F., Prasetyo, I.R., Hardiyanti, M., 2021. Interview Bot for Improving Human Resource Management. 2021 In: International Conference on ICT for Smart Society (ICISS), IEEE, pp. 1–5
Siddig, A., Hines, A., 2019. A Psychologist Chatbot Developing Experience. In: Proceedings of AICS, pp. 200-211
Tambe, P., Cappelli P., Yakubovich, V., 2019. Artificial Intelligence in Human Resources Management: Challenges and a Path Forward. California Management Review, Volume 61(4), pp. 1–28
Yakkundi, S., Vanjare, A., Wavhal, V. and Patankar, S., 2019. Interactive Interview Chatbot. International Research Journal of Engineering and Technology, Volume 6(4), pp. 2746– 2748
